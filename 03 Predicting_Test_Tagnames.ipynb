{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine Learning Internship | Navia Life Care</h1>\n",
    "\n",
    "Name: Uma T V\n",
    "\n",
    "Email: uma.tv1699@gmail.com\n",
    "\n",
    "Roll No: ME17B170\n",
    "\n",
    "Institute: Indian Institute of Technology Madras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3 out of 3</h2>\n",
    "\n",
    "<h3> 03 Predicting Test Tagnames </h3>\n",
    "<p style=\"color:blue\"> This program uses the most efficient model from program 2 and uses that to predict the tagnames of the test images given in electoral-captchas, through individual number splitting analysis and stores the predicted values as filenames of the same images in another folder Predicted_Captchas </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import k_means\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the split and processed individual numbers pixel information\n",
    "\n",
    "train=pd.read_csv('split_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprating into pixel values (features) and labels\n",
    "\n",
    "y_train=train['120']\n",
    "x_train=train.drop('120',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Pipeline with all the models\n",
    "\n",
    "pipe = Pipeline([('pca',IncrementalPCA(n_components=10)),\n",
    "                 ('svc', GridSearchCV(estimator = SVC(), param_grid = {\"C\": [5]}, scoring= 'accuracy', \n",
    "                                      cv = KFold(n_splits=3,shuffle=True,random_state=42),\n",
    "                                      verbose = 1, return_train_score=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 IncrementalPCA(batch_size=None, copy=True, n_components=10,\n",
       "                                whiten=False)),\n",
       "                ('svc',\n",
       "                 GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                              error_score=nan,\n",
       "                              estimator=SVC(C=1.0, break_ties=False,\n",
       "                                            cache_size=200, class_weight=None,\n",
       "                                            coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='scale',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False),\n",
       "                              iid='deprecated', n_jobs=None,\n",
       "                              param_grid={'C': [5]}, pre_dispatch='2*n_jobs',\n",
       "                              refit=True, return_train_score=True,\n",
       "                              scoring='accuracy', verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model to the data\n",
    "\n",
    "pipe.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model pipeline\n",
    "\n",
    "pickle.dump(pipe, open(\"Model.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to convert rgb to grayscale\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load images along with their pixel informations to lists\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    labels=[]\n",
    "    images = []\n",
    "    untouched_images=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        untouched_image=cv2.imread(os.path.join(folder,filename))\n",
    "        img = rgb2gray(imread(os.path.join(folder,filename)))\n",
    "        untouched_images.append(untouched_image)\n",
    "        images.append(img)     \n",
    "    return images, untouched_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the test images (untagged to be predicted ones)\n",
    "\n",
    "test_images, test_untouched_images =load_images_from_folder('electoral-captchas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new directory to save the predicted images with their correct tag as their filename\n",
    "\n",
    "if not os.path.exists('Predicted_Captchas'):\n",
    "    os.makedirs('Predicted_Captchas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the number of rows and columns in split number mini images \n",
    "\n",
    "rows=12\n",
    "cols=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "100 done\n",
      "200 done\n",
      "300 done\n",
      "400 done\n",
      "500 done\n",
      "600 done\n",
      "700 done\n",
      "800 done\n",
      "900 done\n",
      "1000 done\n",
      "1100 done\n",
      "1200 done\n",
      "1300 done\n",
      "1400 done\n"
     ]
    }
   ],
   "source": [
    "# predicting the tag of test images by splitting them into indivual numbers \n",
    "#storing the images along with their correc filename in Predicted_Captchas\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    split_test= pd.DataFrame(columns=[i for i in range(rows*cols)])\n",
    "    df=pd.DataFrame()\n",
    "    arr_prev=0\n",
    "    arr=0\n",
    "    break_=[]\n",
    "    for j in range(test_images[i].shape[1]):\n",
    "        df[j]=test_images[i][:,j]\n",
    "        values=df[j].unique()\n",
    "        sig=0\n",
    "        for k in values:\n",
    "            if(k<0.5): sig=1\n",
    "        if(sig==0): arr=0\n",
    "        else: arr=1\n",
    "        if(arr==1 and arr_prev==0):\n",
    "            if( len(break_)==0 or (j-1) > (break_[-1]+cols)): break_.append(j-1)\n",
    "        arr_prev=arr\n",
    "    df_list=[]\n",
    "    if(len(break_)!=5): \n",
    "        print(\"ERRORRR\")\n",
    "        print(i)\n",
    "    for j in range(len(break_)):\n",
    "        if(break_[j]+cols>130): break_[j]=129-cols\n",
    "        df_list.append(df[df.columns[break_[j]:break_[j]+cols]])\n",
    "        break_row=0\n",
    "        for k in range(42):\n",
    "            for l in df_list[j].columns:\n",
    "                if(df_list[j][l][k]<0.5):\n",
    "                    break_row=k\n",
    "        df_list[j]=df_list[j].loc[break_row-10:break_row+1]\n",
    "    for j in range(len(df_list)):\n",
    "        pixels=[]\n",
    "        for k in df_list[j].columns:\n",
    "            for l in df_list[j].index:\n",
    "                pixels.append(df_list[j][k][l])\n",
    "        temp_df=pd.DataFrame([pixels],columns=[i for i in range(rows*cols)])\n",
    "        split_test=pd.concat([split_test,temp_df])\n",
    "    if(i%100==0): print(i,\"done\")\n",
    "    test_predict = pipe.predict(split_test)\n",
    "    filename=''\n",
    "    for j in range(len(test_predict)):\n",
    "        filename=filename+str(test_predict[j])\n",
    "    cv2.imwrite('Predicted_Captchas/'+filename+'.png',test_untouched_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">Hence, we have successfully predicted the tagnames of the captchas given in electoral_captchas and we have stored the same images with their correct filenames in a new folder Predicted_Captchas. The predictions , on manual inspection are almost 100 percent accurate</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
